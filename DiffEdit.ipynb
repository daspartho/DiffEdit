{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKxPqTCkLuqRHtIsZyDNKx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daspartho/DiffEdit/blob/main/DiffEdit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "OV-osOaO-Q4x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xlLTVh83_QW",
        "outputId": "2a45279c-b249-46b4-dd21-7a4fddf226d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from diffusers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from diffusers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from diffusers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from diffusers) (4.13.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from diffusers) (0.10.1)\n",
            "Requirement already satisfied: Pillow<10.0 in /usr/local/lib/python3.7/dist-packages (from diffusers) (7.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from diffusers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.10.0->diffusers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.10.0->diffusers) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.10.0->diffusers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.10.0->diffusers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.10.0->diffusers) (3.0.9)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->diffusers) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->diffusers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->diffusers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->diffusers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->diffusers) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from diffusers import AutoencoderKL, UNet2DConditionModel, DDIMScheduler\n",
        "import torch\n",
        "from torchvision import transforms as tfms\n",
        "from tqdm.auto import tqdm\n",
        "from PIL import Image\n",
        "from IPython import display\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "if not (Path.home()/'.huggingface'/'token').exists(): \n",
        "    notebook_login()"
      ],
      "metadata": {
        "id": "vkE2gfl95zWA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Models"
      ],
      "metadata": {
        "id": "sTpvtOxn-EK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = CLIPTokenizer.from_pretrained(\n",
        "    \"openai/clip-vit-large-patch14\",\n",
        "    torch_dtype = torch.float16,\n",
        ")\n",
        "\n",
        "text_encoder = CLIPTextModel.from_pretrained(\n",
        "    \"openai/clip-vit-large-patch14\",\n",
        "    torch_dtype = torch.float16,\n",
        ").to(\"cuda\")\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    subfolder = \"vae\",\n",
        "    torch_dtype = torch.float16,\n",
        ").to(\"cuda\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    subfolder = \"unet\",\n",
        "    torch_dtype = torch.float16,\n",
        ").to(\"cuda\")\n",
        "\n",
        "beta_start,beta_end = 0.00085,0.012\n",
        "scheduler = DDIMScheduler(\n",
        "    beta_start=beta_start,\n",
        "    beta_end=beta_end,\n",
        "    beta_schedule=\"scaled_linear\",\n",
        "    num_train_timesteps=1000,\n",
        "    clip_sample=False, \n",
        "    set_alpha_to_one=False,\n",
        ")"
      ],
      "metadata": {
        "id": "E7LAWBIn54yI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoding Encoding functions"
      ],
      "metadata": {
        "id": "dMOS_HN8_KM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(img):\n",
        "    with torch.no_grad():\n",
        "        latent = vae.encode(tfms.ToTensor()(img).unsqueeze(0).to(\"cuda\").half())\n",
        "        latent = 0.18215 * latent.latent_dist.sample()\n",
        "    return latent\n",
        "\n",
        "def decode(latent):\n",
        "    latent = (1 / 0.18215) * latent\n",
        "    with torch.no_grad():\n",
        "        img = vae.decode(latent).sample\n",
        "    img = (img / 2 + 0.5).clamp(0, 1)\n",
        "    img = img.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "    img = (img * 255).round().astype(\"uint8\")\n",
        "    pil_images = [Image.fromarray(image) for image in img]\n",
        "    return pil_images"
      ],
      "metadata": {
        "id": "5yVtBPLX8e4k"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to turn prompts in embeddings"
      ],
      "metadata": {
        "id": "Hs9Rwv7o_teO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_text(prompt):\n",
        "\n",
        "    text_input = tokenizer(\n",
        "        prompt,\n",
        "        padding=\"max_length\",\n",
        "        max_length=tokenizer.model_max_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    text_embedding = text_encoder(\n",
        "        text_input.input_ids.to(\"cuda\")\n",
        "    )[0].half()\n",
        "\n",
        "    uncond_input = tokenizer(\n",
        "        [\"\"],\n",
        "        padding=\"max_length\",\n",
        "        max_length=tokenizer.model_max_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    uncond_embedding = text_encoder(\n",
        "        uncond_input.input_ids.to(\"cuda\")\n",
        "    )[0].half()\n",
        "\n",
        "    return torch.cat([uncond_embedding, text_embedding])"
      ],
      "metadata": {
        "id": "d0dW4BxN_Xzm"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}